{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 NSGA II\n",
    "\n",
    "> Code is inspired from:\n",
    "> \n",
    "> https://medium.com/@rossleecooloh/optimization-algorithm-nsga-ii-and-python-package-deap-fca0be6b2ffc\n",
    ">\n",
    "> https://github.com/DEAP/deap/blob/master/examples/ga/nsga2.py\n",
    ">\n",
    ">  https://github.com/DEAP/deap/blob/master/deap/tools/emo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from distutils.command.build_scripts import first_line_re\n",
    "# Import deque for the stack structure, copy for deep copy nodes\n",
    "from collections import deque\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn \n",
    "\n",
    "import seaborn as sns\n",
    "# Encoding categorical features with preserving the missing values in incomplete features\n",
    "from sklearn.preprocessing import (KBinsDiscretizer, LabelEncoder,\n",
    "                                   OneHotEncoder, OrdinalEncoder,\n",
    "                                   StandardScaler)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import array\n",
    "import random\n",
    "import json\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from math import sqrt\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import benchmarks\n",
    "from deap.benchmarks.tools import diversity, convergence, hypervolume\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define some constants for the genetic algorithm\n",
    "\n",
    "\n",
    "\n",
    "CONSTANTS_DICT = {\n",
    "    \"POPULATION_SIZE\": 100, # number of individuals in each population\n",
    "    \"MAX_GENERATIONS\": 100, # number of generations to run the algorithm\n",
    "    \"CROSSOVER_RATE\": 0.9, # crossover rate should always be 100%, based on slides\n",
    "    \"MUTATION_RATE\": 0.2, # mutation rate\n",
    "    \"CLASSIFIER\":KNeighborsClassifier() , # classifier to use\n",
    "    # \"BOUND_LOW\": 0.0, # lower bound for the features\n",
    "    # \"BOUND_UP\": 1.0, # upper bound for the features\n",
    "    # \"ETA\": 20.0, # crowding degree for mutation  and crossover\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Empty\n",
    "\n",
    "\n",
    "class DatasetPart3:\n",
    "    def __init__(self, df) :\n",
    "        self.df=df\n",
    "        self.df.columns = self.df.columns.str.strip()\n",
    "        self.X = self.df.iloc[:,:-1]\n",
    "        self.y = self.df.iloc[:,-1]\n",
    "        # self.M = self.df.shape[0]  # number of rows\n",
    "    \n",
    "    # @classmethod\n",
    "    # def constructFromFile(cls, filePath):\n",
    "    #     \"\"\"Depends on different ds\"\"\"\n",
    "    #     pass\n",
    "\n",
    "    def getDfWithSelectedFeatures(self, selectedFeatures:list):\n",
    "        \"\"\"No need to avoid FS bias, just based on df\"\"\"\n",
    "        returnedDf = pd.DataFrame()\n",
    "        selectedCount = 0\n",
    "        for i in range(len(selectedFeatures)):\n",
    "            isSelected = True if selectedFeatures[i] > 0.5 else False\n",
    "            if isSelected:\n",
    "                selectedCount += 1\n",
    "                # concat this feature to the returned dataframe\n",
    "                returnedDf = pd.concat([returnedDf,self.df.iloc[:,i]],axis=1)\n",
    "        # concat the class column\n",
    "        returnedDf = pd.concat([returnedDf, self.y],axis=1)\n",
    "        assert returnedDf.empty == False\n",
    "\n",
    "        return returnedDf, selectedCount\n",
    "    \n",
    "    @staticmethod\n",
    "    def run_model(df:pd.DataFrame, classifier=CONSTANTS_DICT[\"CLASSIFIER\"]):\n",
    "\n",
    "        assert df.empty == False\n",
    "        # pipe = Pipeline([\n",
    "        #     ('scaler', StandardScaler()),\n",
    "        #     ('classifier', classifier)\n",
    "        #                  ])\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "        \n",
    "        # pipe.fit(X_train, y_train)\n",
    "        # return pipe.score(X_test, y_test)\n",
    "        \n",
    "        X = df.iloc[:,:-1]\n",
    "        y = df.iloc[:,-1]\n",
    "        \n",
    "        classifier.fit(X, y)\n",
    "        return classifier.score(X, y)\n",
    "        # # # # evaluate the model\n",
    "        # cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=6)\n",
    "        # # return the error\n",
    "        # n_scores = cross_val_score(classifier, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "        # return np.mean(n_scores)\n",
    "        \n",
    "        \n",
    "\n",
    "class Vehicle(DatasetPart3):\n",
    "    def __init__(self, df):\n",
    "        super().__init__(df)\n",
    "    \n",
    "    @classmethod\n",
    "    def constructFromFile(cls, filePath):\n",
    "        df = pd.read_csv(filePath, header=None, delim_whitespace=True)\n",
    "        df.columns = [f\"f_{i}\" for i in range(len(df.columns))]\n",
    "        df.rename(columns = {f'f_{len(df.columns)-1}':'class'}, inplace = True)\n",
    "        return cls(df)\n",
    "    \n",
    "class MuskClean(DatasetPart3):\n",
    "    def __init__(self, df):\n",
    "        super().__init__(df)\n",
    "\n",
    "    @classmethod\n",
    "    def constructFromFile(cls, filePath):\n",
    "        df = pd.read_csv(filePath, header=None)\n",
    "        # ignore the first 2 columns since they are NOT numerical, so it would be betteer to ignore them \n",
    "        df.drop([0,1], axis=1, inplace=True)\n",
    "        df.columns = [f\"f_{i}\" for i in range(len(df.columns))]\n",
    "        df.rename(columns = {f'f_{len(df.columns)-1}':'class'}, inplace = True)\n",
    "        return cls(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 846 entries, 0 to 845\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   f_0     846 non-null    int64 \n",
      " 1   f_1     846 non-null    int64 \n",
      " 2   f_2     846 non-null    int64 \n",
      " 3   f_3     846 non-null    int64 \n",
      " 4   f_4     846 non-null    int64 \n",
      " 5   f_5     846 non-null    int64 \n",
      " 6   f_6     846 non-null    int64 \n",
      " 7   f_7     846 non-null    int64 \n",
      " 8   f_8     846 non-null    int64 \n",
      " 9   f_9     846 non-null    int64 \n",
      " 10  f_10    846 non-null    int64 \n",
      " 11  f_11    846 non-null    int64 \n",
      " 12  f_12    846 non-null    int64 \n",
      " 13  f_13    846 non-null    int64 \n",
      " 14  f_14    846 non-null    int64 \n",
      " 15  f_15    846 non-null    int64 \n",
      " 16  f_16    846 non-null    int64 \n",
      " 17  f_17    846 non-null    int64 \n",
      " 18  class   846 non-null    object\n",
      "dtypes: int64(18), object(1)\n",
      "memory usage: 125.7+ KB\n"
     ]
    }
   ],
   "source": [
    "ds_vehicle = Vehicle.constructFromFile(\"./vehicle/vehicle.dat\")\n",
    "print(len(ds_vehicle.X.columns))\n",
    "ds_vehicle.df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_157</th>\n",
       "      <th>f_158</th>\n",
       "      <th>f_159</th>\n",
       "      <th>f_160</th>\n",
       "      <th>f_161</th>\n",
       "      <th>f_162</th>\n",
       "      <th>f_163</th>\n",
       "      <th>f_164</th>\n",
       "      <th>f_165</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-109</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>-88</td>\n",
       "      <td>-28</td>\n",
       "      <td>-27</td>\n",
       "      <td>...</td>\n",
       "      <td>-74</td>\n",
       "      <td>-129</td>\n",
       "      <td>-120</td>\n",
       "      <td>-38</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120</td>\n",
       "      <td>-39</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>-161</td>\n",
       "      <td>-45</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>-120</td>\n",
       "      <td>-38</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-110</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>-95</td>\n",
       "      <td>-28</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120</td>\n",
       "      <td>-39</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-102</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>-87</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>51</td>\n",
       "      <td>128</td>\n",
       "      <td>144</td>\n",
       "      <td>43</td>\n",
       "      <td>-30</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>49</td>\n",
       "      <td>-199</td>\n",
       "      <td>-161</td>\n",
       "      <td>29</td>\n",
       "      <td>-95</td>\n",
       "      <td>-86</td>\n",
       "      <td>-48</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-246</td>\n",
       "      <td>-209</td>\n",
       "      <td>33</td>\n",
       "      <td>152</td>\n",
       "      <td>134</td>\n",
       "      <td>47</td>\n",
       "      <td>-43</td>\n",
       "      <td>-15</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>38</td>\n",
       "      <td>-123</td>\n",
       "      <td>-139</td>\n",
       "      <td>30</td>\n",
       "      <td>-117</td>\n",
       "      <td>-88</td>\n",
       "      <td>214</td>\n",
       "      <td>-13</td>\n",
       "      <td>-74</td>\n",
       "      <td>-129</td>\n",
       "      <td>...</td>\n",
       "      <td>-226</td>\n",
       "      <td>-210</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>119</td>\n",
       "      <td>79</td>\n",
       "      <td>-28</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>43</td>\n",
       "      <td>-102</td>\n",
       "      <td>-20</td>\n",
       "      <td>-101</td>\n",
       "      <td>-116</td>\n",
       "      <td>200</td>\n",
       "      <td>-166</td>\n",
       "      <td>66</td>\n",
       "      <td>-222</td>\n",
       "      <td>-49</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>136</td>\n",
       "      <td>-15</td>\n",
       "      <td>143</td>\n",
       "      <td>121</td>\n",
       "      <td>55</td>\n",
       "      <td>-37</td>\n",
       "      <td>-19</td>\n",
       "      <td>-36</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>39</td>\n",
       "      <td>-58</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>-117</td>\n",
       "      <td>-92</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>-73</td>\n",
       "      <td>-68</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>-206</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>116</td>\n",
       "      <td>79</td>\n",
       "      <td>-28</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>52</td>\n",
       "      <td>-121</td>\n",
       "      <td>-24</td>\n",
       "      <td>-104</td>\n",
       "      <td>-116</td>\n",
       "      <td>195</td>\n",
       "      <td>-162</td>\n",
       "      <td>76</td>\n",
       "      <td>-226</td>\n",
       "      <td>-56</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>133</td>\n",
       "      <td>-20</td>\n",
       "      <td>-46</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>-14</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f_0  f_1  f_2  f_3  f_4  f_5  f_6  f_7  f_8  f_9  ...  f_157  f_158  \\\n",
       "0     42 -198 -109  -75 -117   11   23  -88  -28  -27  ...    -74   -129   \n",
       "1     42 -191 -142  -65 -117   55   49 -170  -45    5  ...   -302     60   \n",
       "2     42 -191 -142  -75 -117   11   49 -161  -45  -28  ...    -73   -127   \n",
       "3     42 -198 -110  -65 -117   55   23  -95  -28    5  ...   -302     60   \n",
       "4     42 -198 -102  -75 -117   10   24  -87  -28  -28  ...    -73   -127   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "471   49 -199 -161   29  -95  -86  -48    2  112  -79  ...   -246   -209   \n",
       "472   38 -123 -139   30 -117  -88  214  -13  -74 -129  ...   -226   -210   \n",
       "473   43 -102  -20 -101 -116  200 -166   66 -222  -49  ...     32    136   \n",
       "474   39  -58   27   31 -117  -92   85   21  -73  -68  ...   -232   -206   \n",
       "475   52 -121  -24 -104 -116  195 -162   76 -226  -56  ...     34    133   \n",
       "\n",
       "     f_159  f_160  f_161  f_162  f_163  f_164  f_165  class  \n",
       "0     -120    -38     30     48    -37      6     30    1.0  \n",
       "1     -120    -39     31     48    -37      5     30    1.0  \n",
       "2     -120    -38     30     48    -37      5     31    1.0  \n",
       "3     -120    -39     30     48    -37      6     30    1.0  \n",
       "4       51    128    144     43    -30     14     26    1.0  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "471     33    152    134     47    -43    -15    -10    0.0  \n",
       "472     20     55    119     79    -28      4     74    0.0  \n",
       "473    -15    143    121     55    -37    -19    -36    0.0  \n",
       "474     13     45    116     79    -28      3     74    0.0  \n",
       "475    -20    -46     95     98    -14     12     96    0.0  \n",
       "\n",
       "[476 rows x 167 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_mushclean = MuskClean.constructFromFile(\"./musk/clean1.data\")\n",
    "ds_mushclean.df\n",
    "# # len(ds_mushclean.x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/pkg/lib/python3.9/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'MultiObjMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/usr/pkg/lib/python3.9/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# 2 minimum objectives, so -1,-1\n",
    "creator.create(\"MultiObjMin\", base.Fitness, weights=(-1.0, -1.0)) \n",
    "# Individual should be a list of binary values, i.e. a list of 0s and 1s\n",
    "creator.create(\"Individual\", list, fitness=creator.MultiObjMin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define wrapper based fitness evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTransformedDf(df2Transform:pd.DataFrame):\n",
    "#     \"\"\"transform the continous features to discontinous. In other words, due to all features are continous, this functions are used to discretise all continous features.\n",
    "\n",
    "#     KBins is used to discretise the continous features. The number of bins is set to 10. The strategy is set to uniform.\n",
    "    \n",
    "#     Tutorial: https://machinelearningmastery.com/discretization-transforms-for-machine-learning/\n",
    "    \n",
    "#     Args:\n",
    "#         df2Transform (pd.DataFrame): df to transform, all features should be continous\n",
    "        \n",
    "#     \"\"\" \n",
    "#     tempDf = deepcopy(df2Transform)\n",
    "#     tempDf_x = tempDf.iloc[:,:-1]\n",
    "#     tempDf_y = tempDf.iloc[:,-1]\n",
    "#     # tempDf_y = LabelEncoder().fit_transform(tempDf_y)\n",
    "#     # only transform the continous features, ignore Y\n",
    "#     kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "#     tempDf_x = kbins.fit_transform(tempDf_x)\n",
    "#     tempDf = pd.concat([pd.DataFrame(tempDf_x),tempDf_y],axis=1)\n",
    "#     tempDf.columns = [f\"f_{i}\" for i in range(len(tempDf.columns))]\n",
    "#     tempDf.rename(columns = {f'f_{len(tempDf.columns)-1}':'class'}, inplace = True)\n",
    "#     return tempDf\n",
    "\n",
    "def wrapperFitnessEvaluation(ds:DatasetPart3, individual:creator.Individual, \n",
    "                             classifier=CONSTANTS_DICT[\"CLASSIFIER\"]): #KNN by default\n",
    "    df_selected,selected_count = ds.getDfWithSelectedFeatures(individual)\n",
    "    # df_selected = getTransformedDf(df_selected)\n",
    "        \n",
    "    acc_score = DatasetPart3.run_model(df_selected, classifier)\n",
    "    obj1 = 1.0-acc_score # classification error\n",
    "    obj2 = selected_count/len(individual) #ratio of selected features\n",
    "    assert 0<=obj1<=1\n",
    "    assert 0<=obj2<=1\n",
    "    return obj1, obj2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tool box\n",
    "\n",
    "> https://www.researchgate.net/publication/235707001_DEAP_Evolutionary_algorithms_made_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deap import dtm\n",
    "# toolbox is a class contains the operators that we will use in our genetic programming algorithm\n",
    "# it can be also be used as the container of methods which enables us to add new methods to the toolbox \n",
    "def setup_toolbox(ds:DatasetPart3, randSeed:int) -> base.Toolbox:\n",
    "    toolbox = base.Toolbox()\n",
    "    # toolbox.register(\"map\",dtm.map)\n",
    "    \n",
    "    # for population size, we use the random.randint function to generate a random integer in the range [min, max]\n",
    "    random.seed(randSeed)\n",
    "    # register a method to generate random boolean values\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    # register a method to generate random individuals\n",
    "    toolbox.register(\"IndividualCreator\", \n",
    "                     tools.initRepeat, \n",
    "                     creator.Individual, \n",
    "                     toolbox.attr_bool, \n",
    "                     n=len(ds.X.columns) # feature number, exclude the class column\n",
    "                    )\n",
    "    \n",
    "    # N is not specificied, so need to specify number of individuals to generate within each population when we call it later\n",
    "    toolbox.register(\"PopulationCreator\", tools.initRepeat, list, toolbox.IndividualCreator) \n",
    "\n",
    "    # toolbox.register(\"select\", tools.emo.selTournamentDCD)\n",
    "    toolbox.register(\"select\", tools.selNSGA2)\n",
    "    toolbox.register('selectGen1', tools.selTournament, tournsize=2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=CONSTANTS_DICT[\"BOUND_LOW\"], up=CONSTANTS_DICT[\"BOUND_UP\"], eta=CONSTANTS_DICT[\"ETA\"])\n",
    "    # toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=CONSTANTS_DICT[\"BOUND_LOW\"], up=CONSTANTS_DICT[\"BOUND_UP\"], eta=CONSTANTS_DICT[\"ETA\"], indpb=1.0/len(ds.x.columns))\n",
    "    \n",
    "\n",
    "    \n",
    "    toolbox.register(\"mate\", tools.cxUniform, indpb=1.0/len(ds.X.columns)) # TODO: might need to change this to cxOnePoint\n",
    "    # indpb refer to the probability of mutate happening on each gene, it is NOT the same as mutation rate\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=1.0/len(ds.X.columns)) \n",
    "    \n",
    "    toolbox.register(\"evaluate\", wrapperFitnessEvaluation, ds) # need to pass individual:list\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run NSGA once \n",
    "\n",
    "> https://github.dev/DEAP/deap/blob/master/deap/tools/emo.py\n",
    "> https://github.dev/DEAP/deap/blob/master/examples/ga/nsga2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from select import select\n",
    "import time\n",
    "\n",
    "def run_NSGAII(ds:DatasetPart3, randSeed:int, \n",
    "                ngen:int=CONSTANTS_DICT[\"MAX_GENERATIONS\"], \n",
    "                popSize:int=CONSTANTS_DICT[\"POPULATION_SIZE\"]):\n",
    "    # stats\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min, axis=0)\n",
    "    stats.register(\"max\", np.max, axis=0)\n",
    "    stats.register(\"mean\", np.mean, axis = 0)\n",
    "    stats.register(\"std\", np.std, axis=0)\n",
    "    # for record keeping\n",
    "    logbook = tools.Logbook()    \n",
    "    logbook.header = \"gen\", \"mean\", \"std\", \"min\",  \"max\"\n",
    "    \n",
    "    # create toolbox\n",
    "    random.seed(randSeed)\n",
    "    toolbox = setup_toolbox(ds, randSeed)\n",
    "    \n",
    "    # calculate objectives\n",
    "    def evaluate_update_fitness_values(p) :\n",
    "        \"\"\"Update the fitness values of each individual for the given the population\"\"\"\n",
    "        fitnesses = list(map(toolbox.evaluate, p))\n",
    "        for ind, fit in zip(p, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            \n",
    "            \n",
    "            \n",
    "    # create the initial population\n",
    "    pop = toolbox.PopulationCreator(n=popSize)\n",
    "    evaluate_update_fitness_values(pop)\n",
    "    for g in range(ngen):\n",
    "        offspring = algorithms.varAnd(pop, toolbox, \n",
    "                                      cxpb=CONSTANTS_DICT[\"CROSSOVER_RATE\"], \n",
    "                                      mutpb=CONSTANTS_DICT[\"MUTATION_RATE\"])\n",
    "        evaluate_update_fitness_values(offspring)\n",
    "        pop = toolbox.select(pop + offspring, k=len(pop))\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=g,  **record)\n",
    "        print(logbook.stream)\n",
    "    \n",
    "    \n",
    "    # # fronts = tools.emo.sortNondominated(pop,k=popSize,first_front_only=False)\n",
    "    # # for idx,front in enumerate(fronts):\n",
    "    # #     #print(idx,front)\n",
    "    # #     for ind in front:\n",
    "    # #         ind.fitness.values = (idx+1),# change fitness to the order of pareto front\n",
    "    # # offspring = toolbox.selectGen1(pop, len(pop))\n",
    "    # # # apply mate and mutate only once\n",
    "    # # offspring = algorithms.varAnd(offspring,toolbox,\n",
    "    # #                               CONSTANTS_DICT[\"CROSSOVER_RATE\"],\n",
    "    # #                               CONSTANTS_DICT[\"MUTATION_RATE\"]) \n",
    "\n",
    "    # # for gen_counter in range(1,ngen):\n",
    "    # #     combined_population = pop + offspring\n",
    "        \n",
    "    # #     # fitnesses = toolbox.map(toolbox.evaluate, combined_population)\n",
    "    # #     # # print(f\"fitnesses: {fitnesses}\")\n",
    "\n",
    "    # #     # for ind, fit in zip(combined_population, fitnesses):\n",
    "    # #     #     ind.fitness.values = fit\n",
    "    # #     evaluate_fitness_values(combined_population)\n",
    "        \n",
    "    # #     # stats\n",
    "    # #     record = stats.compile(combined_population)\n",
    "    # #     logbook.record(gen=gen_counter,  **record)\n",
    "    # #     print(logbook.stream)\n",
    "\n",
    "        \n",
    "    # #     fronts = tools.emo.sortNondominated(combined_population,\n",
    "    # #                                         k=popSize,\n",
    "    # #                                         first_front_only=False)\n",
    "        \n",
    "    # #     for front in fronts:\n",
    "    # #         tools.emo.assignCrowdingDist(front) # for computing crowding distance\n",
    "            \n",
    "    # #     pop = []\n",
    "    # #     for front in fronts:\n",
    "    # #         pop += front\n",
    "    # #     pop = toolbox.clone(pop)\n",
    "    # #     pop = tools.selNSGA2(pop,k=popSize,nd='standard') # elitism strategy basd on crowded distance\n",
    "\n",
    "    # #     offspring = toolbox.select(pop,popSize) \n",
    "    # #     offspring = toolbox.clone(offspring)\n",
    "    # #     offspring = algorithms.varAnd(offspring,toolbox,\n",
    "    # #                               CONSTANTS_DICT[\"CROSSOVER_RATE\"],\n",
    "    # #                               CONSTANTS_DICT[\"MUTATION_RATE\"]) \n",
    "    # # bestInd = tools.selBest(pop,1)[0]\n",
    "    # # bestFit = bestInd.fitness.values\n",
    "    # # print(\"Final population hypervolume is %f\" % hypervolume(pop, [11.0, 11.0]))\n",
    "    # # return pop, logbook, hypervolume(pop, [11.0, 11.0]) # set of non-dominated individuals solutions\n",
    "\n",
    "    # # This is just to assign the crowding distance to the individuals\n",
    "    # # no actual selection is done\n",
    "    # pop = toolbox.select(pop, len(pop))\n",
    "    # record = stats.compile(pop)\n",
    "    # logbook.record(gen=0, **record)\n",
    "    # print(logbook.stream)\n",
    "\n",
    "    # # Begin the generational process\n",
    "    # for gen_counter in range(1,ngen):\n",
    "        \n",
    "    #     # Vary the pop\n",
    "    #     offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "    #     offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        \n",
    "    #     offspring = algorithms.varAnd(offspring, toolbox, \n",
    "    #                                   cxpb=CONSTANTS_DICT[\"CROSSOVER_RATE\"], \n",
    "    #                                   mutpb=CONSTANTS_DICT[\"MUTATION_RATE\"])\n",
    "           \n",
    "    #     # Evaluate all  offsprings individuals \n",
    "    #     combined_pop = offspring + pop\n",
    "    #     evaluate_update_fitness_values(combined_pop)\n",
    "      \n",
    "    #     # elitism strategy\n",
    "    #     # Select the next generation pop\n",
    "    #     pop = toolbox.select(combined_pop, popSize)\n",
    "    #     # stats\n",
    "    #     record = stats.compile(pop)\n",
    "    #     logbook.record(gen=gen_counter,  **record)\n",
    "    #     print(logbook.stream)\n",
    "        \n",
    "    print(\"Final pop hypervolume is %f\" % hypervolume(pop, [11.0, 11.0]))\n",
    "    return pop, logbook, hypervolume(pop, [11.0, 11.0]) # set of non-dominated individuals solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def run_3_times_with_different_seed(ds:DatasetPart3,\n",
    "                                     title:str, \n",
    "                                     max_gen=CONSTANTS_DICT[\"MAX_GENERATIONS\"],\n",
    "                                     classifier = CONSTANTS_DICT[\"CLASSIFIER\"],\n",
    "                                     randSeed = [i+1 for i in range(3)],\n",
    "                                     run_times=3):\n",
    "    # run 3 times with different seed\n",
    "    population_list = []\n",
    "    logbook_list = []\n",
    "    hypervolume_list = []\n",
    "    \n",
    "    color_list = ['r+','g+','b+','c+','m+','y+','k+']\n",
    "    for i in range(run_times):\n",
    "        print('-'*80)\n",
    "        print('-'*80)\n",
    "        print(title,\"\\nRunning GA with seed: \", randSeed[i])\n",
    "        population, logbook, hypervolume = run_NSGAII(ds, randSeed=randSeed[i], ngen=max_gen, popSize=CONSTANTS_DICT[\"POPULATION_SIZE\"])\n",
    "        population_list.append(population)\n",
    "        logbook_list.append(logbook)\n",
    "        hypervolume_list.append(hypervolume)    \n",
    "        print('-'*80)\n",
    "        print('-'*80)\n",
    "        \n",
    "        # # plot the result\n",
    "        front = tools.emo.sortNondominated(population,len(population))[0]\n",
    "        err_rate = [ind.fitness.values[0] for ind in front]\n",
    "        ratio_selcted = [ind.fitness.values[1] for ind in front]\n",
    "        # for ind in front:\n",
    "        plt.plot(err_rate, ratio_selcted, color_list[i], marker='+', ms=2,\n",
    "                 label = f\"seed {randSeed[i]},hypervolume: {hypervolume}\")\n",
    "        plt.ylabel(\"ratio of selected features\")\n",
    "        plt.xlabel(\"classification error rate\")\n",
    "        plt.title(f\"dataset: {title} \\n Objective space\")\n",
    "        plt.tight_layout()\n",
    "    plt.legend(bbox_to_anchor =(1.3,-0.1), loc='lower center')\n",
    "    plt.show()\n",
    "        \n",
    "        # # fitTuple = [ind.fitness.values for ind in population]\n",
    "            \n",
    "        # # plt.plot(fitTuple[0], fitTuple[1], label=f\"seed {randSeed[i]}\\n hypervolume: {hypervolume}\")\n",
    "        # plt.legend(bbox_to_anchor =(1.3,-0.1), loc='lower center')\n",
    "        # plt.ylabel(\"ratio of selected features\")\n",
    "        # plt.xlabel(\"classification error rate\")\n",
    "        # plt.title(f\"dataset: {title} \\n Objective space\")\n",
    "    # plt.show()\n",
    "        \n",
    "        \n",
    "    # compare error rates of the obtained solutions with that of using the entire feature set.\n",
    "    subset_mean_err_rate = [logbook.select(\"mean\")[-1][0] for logbook in logbook_list]\n",
    "    entire_mean_err_rate = DatasetPart3.run_model(ds.df)\n",
    "    \n",
    "    print(f\"{title}:\\n error rates of the obtained solution: {subset_mean_err_rate}\\n error rate of using the entire feature set: {entire_mean_err_rate}\")\n",
    "        \n",
    "    # print \n",
    "\n",
    "    return population_list, logbook_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "vehicle \n",
      "Running GA with seed:  1\n",
      "gen\tmean                   \tstd                    \tmin                    \tmax                    \n",
      "0  \t[0.22539007 0.44166667]\t[0.03358592 0.12407062]\t[0.178487   0.16666667]\t[0.33687943 0.77777778]\n",
      "1  \t[0.21989362 0.41777778]\t[0.03355702 0.1391065 ]\t[0.17257683 0.16666667]\t[0.33687943 0.77777778]\n",
      "2  \t[0.21738771 0.39611111]\t[0.03941158 0.15064778]\t[0.16312057 0.16666667]\t[0.33687943 0.77777778]\n",
      "3  \t[0.22469267 0.38777778]\t[0.04936714 0.17950205]\t[0.16312057 0.16666667]\t[0.33687943 0.77777778]\n",
      "4  \t[0.22744681 0.38666667]\t[0.05671103 0.16646655]\t[0.16312057 0.16666667]\t[0.31323877 0.72222222]\n",
      "5  \t[0.24310875 0.32666667]\t[0.05747333 0.16429423]\t[0.16312057 0.16666667]\t[0.39479905 0.72222222]\n",
      "6  \t[0.22040189 0.37888889]\t[0.05671602 0.19458408]\t[0.16312057 0.11111111]\t[0.31323877 0.72222222]\n",
      "7  \t[0.18898345 0.46833333]\t[0.03846506 0.18958288]\t[0.16312057 0.11111111]\t[0.31323877 0.72222222]\n",
      "8  \t[0.19301418 0.41166667]\t[0.04108455 0.16045749]\t[0.16312057 0.11111111]\t[0.28250591 0.72222222]\n",
      "9  \t[0.19722222 0.41777778]\t[0.0475102  0.18197816]\t[0.16312057 0.11111111]\t[0.28250591 0.55555556]\n",
      "10 \t[0.16880615 0.52666667]\t[0.02245782 0.09796699]\t[0.1607565  0.11111111]\t[0.28250591 0.61111111]\n",
      "11 \t[0.17427896 0.50166667]\t[0.03077526 0.13204353]\t[0.1607565  0.11111111]\t[0.28250591 0.61111111]\n",
      "12 \t[0.18483452 0.44777778]\t[0.03971443 0.166448  ]\t[0.1607565  0.11111111]\t[0.28250591 0.61111111]\n",
      "13 \t[0.20690307 0.34777778]\t[0.04961947 0.18569522]\t[0.15602837 0.11111111]\t[0.356974   0.61111111]\n",
      "14 \t[0.20992908 0.34111111]\t[0.05516993 0.20442935]\t[0.15602837 0.05555556]\t[0.44562648 0.61111111]\n",
      "15 \t[0.24735225 0.17      ]\t[0.04747791 0.06470255]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "16 \t[0.27823877 0.12666667]\t[0.04016161 0.05504207]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "17 \t[0.28527187 0.11777778]\t[0.04326377 0.04532462]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "18 \t[0.28189125 0.12722222]\t[0.05434537 0.0594704 ]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "19 \t[0.28614657 0.13666667]\t[0.07703858 0.07429504]\t[0.15602837 0.05555556]\t[0.55200946 0.38888889]\n",
      "20 \t[0.28460993 0.15944444]\t[0.10060936 0.0941679 ]\t[0.15602837 0.05555556]\t[0.55200946 0.38888889]\n",
      "21 \t[0.30092199 0.17333333]\t[0.12695125 0.12076914]\t[0.15602837 0.05555556]\t[0.55200946 0.38888889]\n",
      "22 \t[0.38009456 0.10722222]\t[0.11152334 0.0963068 ]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "23 \t[0.4013357  0.09666667]\t[0.09914819 0.10049876]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "24 \t[0.38419622 0.11555556]\t[0.11366199 0.1193294 ]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "25 \t[0.35523641 0.14888889]\t[0.13003486 0.14226562]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "26 \t[0.2944208  0.21888889]\t[0.14081321 0.16001929]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "27 \t[0.17568558 0.35555556]\t[0.06487621 0.08854099]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n",
      "28 \t[0.16699764 0.36555556]\t[0.0442605  0.07122387]\t[0.15602837 0.05555556]\t[0.44562648 0.38888889]\n"
     ]
    }
   ],
   "source": [
    "ds_vehicle = Vehicle.constructFromFile(\"./vehicle/vehicle.dat\")\n",
    "pop_list,_ = run_3_times_with_different_seed(ds_vehicle, \"vehicle\",\n",
    "                                max_gen=100,\n",
    "                                run_times=3)\n",
    "print(f\"Solution \")\n",
    "for i in range(len(pop_list)) :\n",
    "    pop = pop_list[i]\n",
    "    print(\"-\"*60)\n",
    "    print(f\"Pop for run with seed {i+1}:\")\n",
    "    for j in range(len(pop)):\n",
    "        ind = pop[j]\n",
    "        print(f\"Individual: {j}\\n\\tError rate{ind.fitness.values[0]}\\n\\t\\\n",
    "          Ratio of selected features: {ind.fitness.values[1]}\")\n",
    "                                \n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "mushclean \n",
      "Running GA with seed:  1\n",
      "gen\tmean                   \tstd                    \tmin                    \tmax                    \n",
      "0  \t[0.37211658 0.50222222]\t[0.04080185 0.12042107]\t[0.29833613 0.22222222]\t[0.49619608 0.77777778]\n",
      "1  \t[0.35425835 0.43      ]\t[0.04703853 0.13231556]\t[0.29719048 0.16666667]\t[0.49619608 0.77777778]\n",
      "2  \t[0.35013854 0.39166667]\t[0.05652224 0.14831877]\t[0.28133333 0.11111111]\t[0.5215098  0.77777778]\n",
      "3  \t[0.33658815 0.37888889]\t[0.04746543 0.14150426]\t[0.28133333 0.11111111]\t[0.5215098  0.77777778]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=0'>1</a>\u001b[0m ds_mushclean \u001b[39m=\u001b[39m MuskClean\u001b[39m.\u001b[39mconstructFromFile(\u001b[39m\"\u001b[39m\u001b[39m./musk/clean1.data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=1'>2</a>\u001b[0m run_3_times_with_different_seed(ds_vehicle, \u001b[39m\"\u001b[39;49m\u001b[39mmushclean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=2'>3</a>\u001b[0m                                 max_gen\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=3'>4</a>\u001b[0m                                 run_times\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m80\u001b[39m)\n",
      "\u001b[1;32m/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb Cell 18\u001b[0m in \u001b[0;36mrun_3_times_with_different_seed\u001b[0;34m(ds, title, max_gen, classifier, randSeed, run_times)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m80\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(title,\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mRunning GA with seed: \u001b[39m\u001b[39m\"\u001b[39m, randSeed[i])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=17'>18</a>\u001b[0m population, logbook, hypervolume \u001b[39m=\u001b[39m run_NSGAII(ds, randSeed\u001b[39m=\u001b[39;49mrandSeed[i], ngen\u001b[39m=\u001b[39;49mmax_gen, popSize\u001b[39m=\u001b[39;49mCONSTANTS_DICT[\u001b[39m\"\u001b[39;49m\u001b[39mPOPULATION_SIZE\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=18'>19</a>\u001b[0m population_list\u001b[39m.\u001b[39mappend(population)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=19'>20</a>\u001b[0m logbook_list\u001b[39m.\u001b[39mappend(logbook)\n",
      "\u001b[1;32m/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb Cell 18\u001b[0m in \u001b[0;36mrun_NSGAII\u001b[0;34m(ds, randSeed, ngen, popSize)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=106'>107</a>\u001b[0m \u001b[39m# Evaluate all  offsprings individuals \u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=107'>108</a>\u001b[0m combined_pop \u001b[39m=\u001b[39m offspring \u001b[39m+\u001b[39m pop\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=108'>109</a>\u001b[0m evaluate_update_fitness_values(combined_pop)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=110'>111</a>\u001b[0m \u001b[39m# elitism strategy\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=111'>112</a>\u001b[0m \u001b[39m# Select the next generation pop\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=112'>113</a>\u001b[0m pop \u001b[39m=\u001b[39m toolbox\u001b[39m.\u001b[39mselect(combined_pop, popSize)\n",
      "\u001b[1;32m/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb Cell 18\u001b[0m in \u001b[0;36mrun_NSGAII.<locals>.evaluate_update_fitness_values\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=26'>27</a>\u001b[0m fitnesses \u001b[39m=\u001b[39m toolbox\u001b[39m.\u001b[39mmap(toolbox\u001b[39m.\u001b[39mevaluate, p)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=27'>28</a>\u001b[0m \u001b[39m# print(f\"fitnesses: {fitnesses}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=28'>29</a>\u001b[0m \u001b[39m# print(pop)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m ind, fit \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(p, fitnesses):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=30'>31</a>\u001b[0m     ind\u001b[39m.\u001b[39mfitness\u001b[39m.\u001b[39mvalues \u001b[39m=\u001b[39m fit\n",
      "\u001b[1;32m/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb Cell 18\u001b[0m in \u001b[0;36mwrapperFitnessEvaluation\u001b[0;34m(ds, individual, classifier)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=25'>26</a>\u001b[0m df_selected,selected_count \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mgetDfWithSelectedFeatures(individual)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=26'>27</a>\u001b[0m \u001b[39m# df_selected = getTransformedDf(df_selected)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=28'>29</a>\u001b[0m acc_score \u001b[39m=\u001b[39m DatasetPart3\u001b[39m.\u001b[39;49mrun_model(df_selected, classifier)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=29'>30</a>\u001b[0m obj1 \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\u001b[39m-\u001b[39macc_score \u001b[39m# classification error\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=30'>31</a>\u001b[0m obj2 \u001b[39m=\u001b[39m selected_count\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(individual) \u001b[39m#ratio of selected features\u001b[39;00m\n",
      "\u001b[1;32m/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb Cell 18\u001b[0m in \u001b[0;36mDatasetPart3.run_model\u001b[0;34m(df, classifier)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=49'>50</a>\u001b[0m cv \u001b[39m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=50'>51</a>\u001b[0m \u001b[39m# return the error\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=51'>52</a>\u001b[0m n_scores \u001b[39m=\u001b[39m cross_val_score(classifier, X, y, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, cv\u001b[39m=\u001b[39;49mcv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, error_score\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mraise\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zhouyun/Desktop/aiml426-a1/p3/p3.ipynb#ch0000016?line=52'>53</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(n_scores)\n",
      "File \u001b[0;32m/usr/pkg/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:385\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    383\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 385\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(estimator\u001b[39m=\u001b[39;49mestimator, X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    386\u001b[0m                             scoring\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m'\u001b[39;49m: scorer}, cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    387\u001b[0m                             n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    388\u001b[0m                             fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    389\u001b[0m                             pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    390\u001b[0m                             error_score\u001b[39m=\u001b[39;49merror_score)\n\u001b[1;32m    391\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m'\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/pkg/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:230\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    229\u001b[0m                     pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 230\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    231\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    232\u001b[0m         clone(estimator), X, y, scorers, train, test, verbose, \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    233\u001b[0m         fit_params, return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    234\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    235\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score)\n\u001b[1;32m    236\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    238\u001b[0m zipped_scores \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mscores))\n\u001b[1;32m    239\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m/usr/pkg/lib/python3.9/site-packages/joblib/parallel.py:1066\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mstop_call()\n\u001b[1;32m   1065\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_managed_backend:\n\u001b[0;32m-> 1066\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_terminate_backend()\n\u001b[1;32m   1067\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[1;32m   1068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pickle_cache \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/pkg/lib/python3.9/site-packages/joblib/parallel.py:759\u001b[0m, in \u001b[0;36mParallel._terminate_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_terminate_backend\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    758\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 759\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mterminate()\n",
      "File \u001b[0;32m/usr/pkg/lib/python3.9/site-packages/joblib/_parallel_backends.py:551\u001b[0m, in \u001b[0;36mLokyBackend.terminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mterminate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    547\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m         \u001b[39m# Don't terminate the workers as we want to reuse them in later\u001b[39;00m\n\u001b[1;32m    549\u001b[0m         \u001b[39m# calls, but cleanup the temporary resources that the Parallel call\u001b[39;00m\n\u001b[1;32m    550\u001b[0m         \u001b[39m# created. This 'hack' requires a private, low-level operation.\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_workers\u001b[39m.\u001b[39;49m_temp_folder_manager\u001b[39m.\u001b[39;49m_unlink_temporary_resources(\n\u001b[1;32m    552\u001b[0m             context_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel\u001b[39m.\u001b[39;49m_id\n\u001b[1;32m    553\u001b[0m         )\n\u001b[1;32m    554\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    556\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_batch_stats()\n",
      "File \u001b[0;32m/usr/pkg/lib/python3.9/site-packages/joblib/_memmapping_reducer.py:627\u001b[0m, in \u001b[0;36mTemporaryResourcesManager._unlink_temporary_resources\u001b[0;34m(self, context_id)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(temp_folder):\n\u001b[1;32m    624\u001b[0m     resource_tracker\u001b[39m.\u001b[39mmaybe_unlink(\n\u001b[1;32m    625\u001b[0m         os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(temp_folder, filename), \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    626\u001b[0m     )\n\u001b[0;32m--> 627\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_delete_folder(\n\u001b[1;32m    628\u001b[0m     allow_non_empty\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, context_id\u001b[39m=\u001b[39;49mcontext_id\n\u001b[1;32m    629\u001b[0m )\n",
      "File \u001b[0;32m/usr/pkg/lib/python3.9/site-packages/joblib/_memmapping_reducer.py:658\u001b[0m, in \u001b[0;36mTemporaryResourcesManager._try_delete_folder\u001b[0;34m(self, allow_non_empty, context_id)\u001b[0m\n\u001b[1;32m    654\u001b[0m     delete_folder(\n\u001b[1;32m    655\u001b[0m         temp_folder, allow_non_empty\u001b[39m=\u001b[39mallow_non_empty\n\u001b[1;32m    656\u001b[0m     )\n\u001b[1;32m    657\u001b[0m     \u001b[39m# Now that this folder is deleted, we can forget about it\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unregister_context(context_id)\n\u001b[1;32m    660\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     \u001b[39m# Temporary folder cannot be deleted right now. No need to\u001b[39;00m\n\u001b[1;32m    662\u001b[0m     \u001b[39m# handle it though, as this folder will be cleaned up by an\u001b[39;00m\n\u001b[1;32m    663\u001b[0m     \u001b[39m# atexit finalizer registered by the memmapping_reducer.\u001b[39;00m\n\u001b[1;32m    664\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/pkg/lib/python3.9/site-packages/joblib/_memmapping_reducer.py:576\u001b[0m, in \u001b[0;36mTemporaryResourcesManager._unregister_context\u001b[0;34m(self, context_id)\u001b[0m\n\u001b[1;32m    573\u001b[0m finalizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalizers[context_id]\n\u001b[1;32m    575\u001b[0m resource_tracker\u001b[39m.\u001b[39munregister(temp_folder, \u001b[39m\"\u001b[39m\u001b[39mfolder\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 576\u001b[0m atexit\u001b[39m.\u001b[39;49munregister(finalizer)\n\u001b[1;32m    578\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_temp_folders\u001b[39m.\u001b[39mpop(context_id)\n\u001b[1;32m    579\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalizers\u001b[39m.\u001b[39mpop(context_id)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds_mushclean = MuskClean.constructFromFile(\"./musk/clean1.data\")\n",
    "run_3_times_with_different_seed(ds_vehicle, \"mushclean\",\n",
    "                                max_gen=100,\n",
    "                                run_times=3)\n",
    "print(\"-\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52da647447b8fe2208076266408c42f82750713fb5b92055dee0a0742687bf52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
