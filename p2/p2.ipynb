{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reading the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature52</th>\n",
       "      <th>feature53</th>\n",
       "      <th>feature54</th>\n",
       "      <th>feature55</th>\n",
       "      <th>feature56</th>\n",
       "      <th>feature57</th>\n",
       "      <th>feature58</th>\n",
       "      <th>feature59</th>\n",
       "      <th>feature60</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0      0.0200    0.0371    0.0428    0.0207    0.0954    0.0986    0.1539   \n",
       "1      0.0453    0.0523    0.0843    0.0689    0.1183    0.2583    0.2156   \n",
       "2      0.0262    0.0582    0.1099    0.1083    0.0974    0.2280    0.2431   \n",
       "3      0.0100    0.0171    0.0623    0.0205    0.0205    0.0368    0.1098   \n",
       "4      0.0762    0.0666    0.0481    0.0394    0.0590    0.0649    0.1209   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "203    0.0187    0.0346    0.0168    0.0177    0.0393    0.1630    0.2028   \n",
       "204    0.0323    0.0101    0.0298    0.0564    0.0760    0.0958    0.0990   \n",
       "205    0.0522    0.0437    0.0180    0.0292    0.0351    0.1171    0.1257   \n",
       "206    0.0303    0.0353    0.0490    0.0608    0.0167    0.1354    0.1465   \n",
       "207    0.0260    0.0363    0.0136    0.0272    0.0214    0.0338    0.0655   \n",
       "\n",
       "     feature8  feature9  feature10  ...  feature52  feature53  feature54  \\\n",
       "0      0.1601    0.3109     0.2111  ...     0.0027     0.0065     0.0159   \n",
       "1      0.3481    0.3337     0.2872  ...     0.0084     0.0089     0.0048   \n",
       "2      0.3771    0.5598     0.6194  ...     0.0232     0.0166     0.0095   \n",
       "3      0.1276    0.0598     0.1264  ...     0.0121     0.0036     0.0150   \n",
       "4      0.2467    0.3564     0.4459  ...     0.0031     0.0054     0.0105   \n",
       "..        ...       ...        ...  ...        ...        ...        ...   \n",
       "203    0.1694    0.2328     0.2684  ...     0.0116     0.0098     0.0199   \n",
       "204    0.1018    0.1030     0.2154  ...     0.0061     0.0093     0.0135   \n",
       "205    0.1178    0.1258     0.2529  ...     0.0160     0.0029     0.0051   \n",
       "206    0.1123    0.1945     0.2354  ...     0.0086     0.0046     0.0126   \n",
       "207    0.1400    0.1843     0.2354  ...     0.0146     0.0129     0.0047   \n",
       "\n",
       "     feature55  feature56  feature57  feature58  feature59  feature60  class  \n",
       "0       0.0072     0.0167     0.0180     0.0084     0.0090     0.0032      1  \n",
       "1       0.0094     0.0191     0.0140     0.0049     0.0052     0.0044      1  \n",
       "2       0.0180     0.0244     0.0316     0.0164     0.0095     0.0078      1  \n",
       "3       0.0085     0.0073     0.0050     0.0044     0.0040     0.0117      1  \n",
       "4       0.0110     0.0015     0.0072     0.0048     0.0107     0.0094      1  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "203     0.0033     0.0101     0.0065     0.0115     0.0193     0.0157      2  \n",
       "204     0.0063     0.0063     0.0034     0.0032     0.0062     0.0067      2  \n",
       "205     0.0062     0.0089     0.0140     0.0138     0.0077     0.0031      2  \n",
       "206     0.0036     0.0035     0.0034     0.0079     0.0036     0.0048      2  \n",
       "207     0.0039     0.0061     0.0040     0.0036     0.0061     0.0115      2  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from distutils.command.build_scripts import first_line_re\n",
    "from tkinter.tix import COLUMN\n",
    "# Import deque for the stack structure, copy for deep copy nodes\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class DatasetPart2:\n",
    "    def __init__(self,df):\n",
    "        self.df=df\n",
    "        self.x = self.df.iloc[:,:-1]\n",
    "        self.y = self.df.iloc[:,-1]\n",
    "        # self.y = self.df.iloc[:-1]\n",
    "\n",
    "    @classmethod\n",
    "    def constructFromFile(cls,filePath):\n",
    "        df = pd.read_csv(filePath,header=None)\n",
    "        df.columns = [f\"feature{i+1}\" for i in range(len(df.columns))]\n",
    "        df.rename(columns = {f'feature{len(df.columns)}':'class'}, inplace = True)\n",
    "        return cls(df) \n",
    "\n",
    "class Sonar(DatasetPart2):\n",
    "    def __init__(self,df):\n",
    "        super().__init__(df)\n",
    "    \n",
    "class Wbcd(DatasetPart2):\n",
    "    def __init__(self,df):\n",
    "        super().__init__(df)\n",
    "\n",
    "ds_sonar  = Sonar.constructFromFile(\"./sonar/sonar.data\")\n",
    "ds_wbcd = Wbcd.constructFromFile(\"./wbcd/wbcd.data\")\n",
    "ds_wbcd.df\n",
    "ds_sonar.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define some constants for the genetic algorithm\n",
    "CONSTANTS_DICT = {\n",
    "    \"POPULATION_SIZE\": 100, # number of individuals in each population\n",
    "    \"MAX_GENERATIONS\": 250, # number of generations to run the algorithm\n",
    "    \"CROSSOVER_RATE\": 1.0, # crossover rate should always be 100%, based on slides\n",
    "    \"MUTATION_RATE\": 0.2, # mutation rate\n",
    "    \"ELITIST_PERCENTAGE\": 0.05, # percentage of the best individuals to keep in the next generation\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use **Creator** to define the type of individuals and fitness classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/pkg/lib/python3.9/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/usr/pkg/lib/python3.9/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "from asyncio import constants\n",
    "from json import tool\n",
    "from deap import creator, base, gp, tools, algorithms # core functionality of DEAP\n",
    "import array\n",
    "import random\n",
    "import json\n",
    "import math # for checking the fitness of an individual, i.e. math.isinf(weight)\n",
    "import matplotlib.pyplot as plt\n",
    "# Python internal operators for object comparisons, \n",
    "# logical comparisons, arithmetic operations, and sequence operations\n",
    "import operator \n",
    "\n",
    "# creator is  usually used to define the type of the individual and fitness classes\n",
    "\n",
    "# goal:to maximize the value and do not exceed the capacity of the knapsack\n",
    "# define strategies with different priorities for optimizing multiple goals by using FitnessCompound\n",
    "# 1 for maximize value, -1 for minimize weight, \n",
    "# creator.create(\"FitnessCompound\", base.Fitness, weights=(1.0,-1.0)) \n",
    " \n",
    "# according to slide, fitness value has been reduced to 1 dimension, so just use FitnessMax\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "# Individual should be a list of binary values, i.e. a list of 0s and 1s\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define the evaluate function for **FilterGA** and **WrapperGA**.\n",
    ">\n",
    "> Inspired by the slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateFilterGA(ds:DatasetPart2, individual:creator.Individual): \n",
    "    \n",
    "    pass\n",
    "\n",
    "def evaluateWrapperGA(ds:DatasetPart2, individual:creator.Individual): \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup toolbox for registering the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# toolbox is a class contains the operators that we will use in our genetic programming algorithm\n",
    "# it can be also be used as the container of methods which enables us to add new methods to the toolbox \n",
    "def setup_toolbox(ds:DatasetPart2, evaluateFunction,randSeed:int) -> base.Toolbox:\n",
    "    toolbox = base.Toolbox()\n",
    "    # for population size, we use the random.randint function to generate a random integer in the range [min, max]\n",
    "    random.seed(randSeed)\n",
    "    # register a method to generate random boolean values\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    # register a method to generate random individuals\n",
    "    toolbox.register(\"IndividualCreator\", \n",
    "                     tools.initRepeat, \n",
    "                     creator.Individual, \n",
    "                     toolbox.attr_bool, \n",
    "                     n=len(ds.x.columns) # feature number, exclude the class column\n",
    "                    )\n",
    "    \n",
    "    # N is not specificied, so need to specify number of individuals to generate within each population when we call it later\n",
    "    toolbox.register(\"PopulationCreator\", tools.initRepeat, list, toolbox.IndividualCreator) \n",
    "    \n",
    "    toolbox.register(\"elitism\", tools.selBest, k=int(CONSTANTS_DICT[\"ELITIST_PERCENTAGE\"]*ds.df.shape[0]))\n",
    "    toolbox.register(\"select\", tools.selTournament, k=2, tournsize=3)\n",
    "    \n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint) # TODO: might need to change this to cxOnePoint\n",
    "    # indpb refer to the probability of mutate happening on each gene, it is NOT the same as mutation rate\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=1.0/ds.M) # TODO: might need to change this to mutUniformInt\n",
    "    # local search operator\n",
    "    # toolbox.register(\"local_search\", algorithms)\n",
    "    \n",
    "    \n",
    "    # register the evaluation function\n",
    "    toolbox.register(\"evaluate\", evaluateFunction,ds) # register a method to evaluate the fitness of an individual\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from select import select\n",
    "import time\n",
    "from turtle import update\n",
    "\n",
    "def run_GA_framework(ds:DatasetPart2, max_gen= CONSTANTS_DICT[\"MAX_GENERATIONS\"] ,randSeed:int=1) -> creator.Individual:\n",
    "    '''\n",
    "    Run the genetic algorithm framework\n",
    "    '''\n",
    "    # for toolbox\n",
    "    random.seed(randSeed)\n",
    "    toolbox = setup_toolbox(ds,randSeed)\n",
    "    # for record keeping\n",
    "    logbook = tools.Logbook()    \n",
    "    # assign the stats for recording the computational time\n",
    "    stats = tools.Statistics()\n",
    "    stats.register(\"mean\", np.mean, axis = 0)\n",
    "    stats.register(\"std\", np.std, axis=0)\n",
    "  \n",
    "    # create the initial population\n",
    "    population = toolbox.PopulationCreator(n=CONSTANTS_DICT[\"POPULATION_SIZE\"])\n",
    "    \n",
    "    # # evaluate the fitness of the current population, and assign the fitness to each individual\n",
    "    # evaluate_fitness_values(population)\n",
    "    def evaluate_fitness_values(pop) -> None:\n",
    "        \"\"\"Update the fitness values of each individual for the given the population\"\"\"\n",
    "        fitnesses = list(map(toolbox.evaluate, pop))\n",
    "        for ind, fit in zip(pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "    \n",
    "    \n",
    "    best_feasible_individual = None\n",
    "    computation_time_list = [] \n",
    "    # start the evolution\n",
    "    for gen_counter in range(max_gen):\n",
    "        # assign the fitness to each individual in the current generation \n",
    "        evaluate_fitness_values(population)\n",
    "        # for recording the time spent on each generation\n",
    "        genStartTime = time.time()\n",
    "        time_cost = computation_time_list[-1] - genStartTime if len(computation_time_list) > 0 \\\n",
    "                                                             else 0.0\n",
    "        computation_time_list.append(time_cost)\n",
    "        # for visualizing whether the algorithm is still running\n",
    "        best_feasible_individual = tools.selBest(population, k=5)[0]\n",
    "        best_fitness = best_feasible_individual.fitness.values[0]\n",
    "        # record the statistics of the current generation\n",
    "        record = stats.compile(computation_time_list) \n",
    "        logbook.record(gen=gen_counter,best_fitness=best_fitness, **record)\n",
    "        \n",
    "        # apply elitism to obtain the best individuals in the current generation\n",
    "        offspring = toolbox.elitism(population)\n",
    "\n",
    "        # repeat until the offspring has the same size as the population\n",
    "        while len(offspring) < CONSTANTS_DICT[\"POPULATION_SIZE\"]:\n",
    "            # apply selection\n",
    "            parent1,parent2 = toolbox.select(population)\n",
    "\n",
    "            # apply crossover\n",
    "            c1,c2 = toolbox.mate(copy.deepcopy(parent1),copy.deepcopy(parent2))\n",
    "            \n",
    "            # apply mutation to the children\n",
    "            for child in [c1,c2]:\n",
    "                if random.random() < CONSTANTS_DICT[\"MUTATION_RATE\"]:\n",
    "                    toolbox.mutate(child)\n",
    "                    del child.fitness.values\n",
    "                # append the children to the offspring\n",
    "                offspring.append(child)\n",
    "            # TODO: apply local search to the children\n",
    "            # annoying, time consuming, not implemented yet although Yi's github got tutorial\n",
    "\n",
    "        # replace the current population with the offspring new gwneration\n",
    "        population[:] = offspring\n",
    "        \n",
    "           \n",
    "    return best_feasible_individual, logbook, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_5_times_with_different_seeds(ds:DatasetPart2, title:str, max_gen=CONSTANTS_DICT[\"MAX_GENERATIONS\"],randSeed = [i+1 for i in range(5)],run_times=5):\n",
    "    '''\n",
    "    Run the GA framework 5 times with different seeds\n",
    "    '''\n",
    "    best_5_avg_fitness_list, best_individual_list = [],[]\n",
    "    gen = None\n",
    "    for i in range(run_times):\n",
    "        best_feasible_individual,logbook,stats = run_GA_framework(ds,max_gen,randSeed[i])\n",
    "        best_individual_list.append(best_feasible_individual)\n",
    "        print('-'*80)\n",
    "        print('-'*80)\n",
    "        print(\"Running GA with seed: \", randSeed[i])\n",
    "        print('Best fitness: ', best_feasible_individual.fitness.values[0])\n",
    "        print('Best value: ', get_weight_value_attrs_for_given_individual(ds,best_feasible_individual)[\"best_ind_value\"])\n",
    "        print('Best weight: ', get_weight_value_attrs_for_given_individual(ds,best_feasible_individual)[\"best_ind_weight\"])\n",
    "        print('Best chromosome: ', get_weight_value_attrs_for_given_individual(ds,best_feasible_individual)[\"best_ind_chromosome\"])\n",
    "        print(\"FOllowing are the statistics for each generation with the seed: \", randSeed[i])\n",
    "        print('-'*80)\n",
    "        logbook.header = \"gen\", \"avg\", \"std\", \"min\", \"max\", \"best_ind_value\", \"best_ind_weight\", \"best_5_avg_fitness\",\"best_ind_chromosome\"\n",
    "        print(logbook)\n",
    "        gen = logbook.select(\"gen\")\n",
    "        # best_feasible_individuals.append(best_feasible_individual)\n",
    "        best_5_avg_fitness_list.append( logbook.select(\"best_5_avg_fitness\"))\n",
    "        print('-'*80)\n",
    "        print('-'*80)\n",
    "        print('-'*80)\n",
    "    \n",
    "    for i in range(run_times):\n",
    "        plt.plot(gen, best_5_avg_fitness_list[i], label=f\"Seed: {str(randSeed[i])}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        # print(best_5_avg_fitness_list[i])\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Average Fitness of 5 best solutions\")\n",
    "    plt.title(f\"dataset: {title}\\n 5 Curves for 5 runs \")\n",
    "    # for addressing the issue of log scale, which is\n",
    "    # very large and a very small fitness values in a plot\n",
    "    needSymlog = lambda y_values : min(y_values) < -1e-3\n",
    "    if needSymlog(best_5_avg_fitness_list[0]):\n",
    "        plt.yscale('symlog') \n",
    "    plt.show()\n",
    "    \n",
    "    # OR just one curve??\n",
    "    avg_5runs = []\n",
    "    for g in range(len(gen)):\n",
    "        # for i in range(5):\n",
    "        #     avg_5runs.append(best_5_avg_fitness_list[i][g])\n",
    "        avg_5runs.append( np.mean([ best_5_avg_fitness_list[i][g] for i in range(run_times) ]) )\n",
    "        \n",
    "    # fig, ax1 = plt.subplots()\n",
    "    plt.plot(gen, avg_5runs, label=\"avg fitness for 5 runs and 5 best ind \")\n",
    "        # plt.legend(loc=\"lower right\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Average Fitness of 5 best solutions from 5 runs\")\n",
    "    plt.title(f\"dataset: {title}\\n Curve for average fitness of 5 best solutions from 5 runs\")\n",
    "    # for addressing the issue of log scale, which is\n",
    "    # very large and a very small fitness values in a plot\n",
    "    if needSymlog(best_5_avg_fitness_list[0]):\n",
    "        plt.yscale('symlog') \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # print out best individual from each run\n",
    "    for i in range(len(best_individual_list)):\n",
    "        print(f\"\\nBest individual for seed {str(randSeed[i])}:\\\n",
    "              \\n\\t {best_individual_list[i]}\\\n",
    "              \\n\\t Fitness: {best_individual_list[i].fitness.values[0]}\\\n",
    "              \\n\\t Value: {get_weight_value_attrs_for_given_individual(ds,best_individual_list[i])['best_ind_value']}\\\n",
    "              \\n\\t Weight: {get_weight_value_attrs_for_given_individual(ds,best_individual_list[i])['best_ind_weight']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52da647447b8fe2208076266408c42f82750713fb5b92055dee0a0742687bf52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
